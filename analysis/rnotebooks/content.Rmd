---
title: "Section 4: Content analyses"
output: 
  html_document:
    toc: true
    toc_depth: 2

---

*Note: the analyses in this notebook expect certain files to have already been created by the preprocessing.Rmd and structure.ipynb notebooks*

# Import data

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
library(ggthemes)
library(tm)
library(tidyboot)
library(xtable)
library(entropy)
library(useful)
library(viridis)
library(broom)
library(gganimate)
library(modeest)

# reticulate lets us import npy files with numpy python package
library(reticulate)
np <- import("numpy")

source('../utils/analysis_helpers.R')
```

# Section 4 | RESULTS: CHARACTERIZING THE DYNAMICS OF SEMANTIC CONTENT

```{r}
# All analyses reported on sequential cued version of task
d <- read_csv('../../data/tangramsSequential_collapsed.csv', col_types = 'ciiccil')
```


## Section 4.1: Initially distinctive words are more likely to conventionalize

```{r}
distinctiveness_d <- read.csv("../outputs/PMI.csv", header = TRUE) %>%
  mutate(finalRoundMatch = ifelse(finalRoundMatch == 'True', 1, 0)) %>%
  filter(!is.na(tf.idf)) %>% 
  mutate(num_tangrams_occurred_with =  round(1 / ((2^tf.idf) /12))) 
```

look at how often final round occurred on early round

```{r}
distinctiveness_d %>% 
  mutate(didNotOccurOnFirstRound = num_tangrams_occurred_with == 0) %>% 
  group_by(finalRoundMatch, didNotOccurOnFirstRound) %>% 
  tally()
```

stats

```{r}
distinctiveness_d %>% 
  filter(num_tangrams_occurred_with > 0 ) %>%
  glmer(finalRoundMatch ~ num_tangrams_occurred_with + 
            (1 + num_tangrams_occurred_with | intendedName) + 
            (1 + num_tangrams_occurred_with | gameid), 
        family = 'binomial', 
        control = glmerControl(optCtrl = list(maxfun = 200000)), 
        data = .) %>%
  summary()
```

```{r}
distinctiveness_d %>%
  filter(num_tangrams_occurred_with > 0) %>%
  group_by(num_tangrams_occurred_with) %>%
  tidyboot_mean(finalRoundMatch) %>%
  rename(sample_size = n) %>%
  ggplot(aes(x = as.integer(num_tangrams_occurred_with), y =empirical_stat)) +
    geom_point(aes(size = sample_size), stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.1) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 2), se = F) +
    ylim(0, .22) +
    ylab('% appearing in final utterance') +
    xlab('distinctiveness of word in initial utterance (# tangrams)') +
    xlim(0,12) +
    scale_x_continuous(breaks = c(1,3, 5,7,9,11))+
    theme_few() +
    theme(aspect.ratio = 1)

ggsave('../../writing/figs/distinctiveness.pdf',  height = 7, width = 10, units = 'cm', useDingbats = F)
```

Alternatively, we can do a nonparametric analysis.
Draw a random word from each tangram/gameid pair and look at the percentage that match with round 6.
This gives a null distribution. 
Then we can take the highest PMI word (or words) for each tangram/gameid pair and look at the percentage of *those* that match. 
We see that it's much higher than expected under the null.

```{r}
nonparametric_ds = seq_len(1000) %>%
  map_dbl(~ { distinctiveness_d %>%
    group_by(intendedName, gameid) %>%
    sample_n(1) %>%
      ungroup() %>%
      summarize(m = mean(finalRoundMatch)) %>%
      pull(m)})
    
highest <- seq_len(1000) %>%
  map_dbl(~ { distinctiveness_d %>%
    group_by(intendedName, gameid) %>%
    filter(num_tangrams_occurred_with == min(num_tangrams_occurred_with)) %>%
    sample_n(1) %>%
    ungroup() %>%
    summarize(m = mean(finalRoundMatch)) %>%
    pull(m)})
    
cat('range for permuted=', sort(nonparametric_ds)[1], sort(nonparametric_ds)[1000])
cat('range for highest=', sort(highest)[1], sort(highest)[1000])
```

## Section 4.2: Semantic meaning diverges across pairs and stabilizes within pairs

```{r}
M_mat = read_csv('../outputs/meta_tangrams_embeddings.csv', col_types = "nccnlc", na = c('[nan]')) %>%
  mutate(feature_ind = X1 + 1, # need to correct for R's (terrible) 1-indexing...
         gameID = gameid,
         target = intendedName,
         repetition = as.numeric(repetitionNum)) #%>% 
F_mat <- np$load('../outputs/feats_tangrams_embeddings_rawavg.npy')
```

### Utterances are more similar overall within games than between games

```{r}
combined.df <- compute_within_vs_across(M_mat, F_mat)

true_dprime = dprime(combined.df)

permuted_dprimes <- seq_len(1000) %>%
  map_dbl(~ dprime(combined.df %>% mutate(source = sample(source))))

cat('CI for permuted=', sort(permuted_dprimes)[25], sort(permuted_dprimes)[975])
cat('true=', true_dprime)

combined.df %>%
  ggplot(aes(x = empirical_stat, fill = source)) +
    geom_density(adjust = 1.5, alpha = .5) +
    #facet_wrap(~ target) +
    xlab('pairwise cosine similarity') +
    theme_few()

ggsave('../../writing/figs/across_vs_within.pdf',  height = 7, width = 10, units = 'cm', useDingbats = F)
```

### Utterances become increasingly consistent within interaction

Stats 

```{r}
true_lmer.within <- make_within_df(M_mat, F_mat, 'cosine') %>% 
  filter(rep2 == rep1 + 1) %>% 
  ungroup()

true_lmer.within.out <- true_lmer.within %>%
  lmer(sim ~ poly(rep1, 2) + 
         (1 + poly(rep1, 2) | gameID) + 
         (1 + poly(rep1, 2) | target), 
       data = .)

summary(true_lmer.within.out)

cat('true for within analysis=', 
    tidy(true_lmer.within.out, effects = 'fixed') %>% 
       filter(term == 'poly(rep1, 2)1') %>%
       pull(estimate))

permuted.within <- compute_permuted_estimates(M_mat, F_mat, 'within', 100)
cat('CI for within analysis=', sort(permuted.within)[2], sort(permuted.within)[98])
```

Viz

```{r}
combined.within <- combine_empirical_and_baselines(M_mat, F_mat, 'within', 2)

combined.within %>%
  mutate(sample_id = fct_relevel(sample_id, 'empirical', 'baseline')) %>%
  ggplot(aes(x = IV, y = empirical_stat, color = sample_id, linetype = sample_id, group = sample_id)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) + 
    geom_line()  +
    scale_x_discrete(labels = c('(1,2)','(2,3)', '(3,4)', '(4,5)', '(5,6)' )) +
    ylim(0.4, 1) +
    ylab('cosine similarity') +
    ggtitle('convergence within game') +
    theme_few() +
    xlab('repetition pair') +
    guides(color = F, fill = F) +
    theme(aspect.ratio = 1, legend.position = c(0.6, 0.5), text = element_text(size=18), 
          element_line(size=1), element_rect(size=2, color="#00000"))

ggsave('../../writing/figs/stability_mean.pdf', height = 10, width = 10, units = 'cm', useDingbats = F)
```

### Utterances become increasingly different across interactions

Stats 

```{r}
true_lmer.across <- M_mat %>% 
   group_by(target, repetition) %>%  
   do(flatten_sim_matrix(get_sim_matrix(., F_mat, method = 'cosine'), .$gameID)) %>% 
  ungroup() %>%
  mutate(target = factor(target))

true_lmer.across.out <- true_lmer.across %>%
  lmer(sim ~ poly(repetition, 2) + (1 +poly(repetition, 2)  | target), 
       control = lmerControl(optimizer ='optimx', 
                             optCtrl=list(method='nlminb')),  
       data = .)

summary(true_lmer.across.out)
cat('true for within analysis=', (tidy(true_lmer.across.out, effects = 'fixed') %>% filter(term == 'poly(repetition, 2)1'))$estimate)

permuted.across <- compute_permuted_estimates(M_mat, F_mat, 'across', 100)
cat('CI for within analysis=', sort(permuted.across)[2], sort(permuted.across)[99])
```

Viz 

```{r}
combined.across <- combine_empirical_and_baselines(M_mat, F_mat, 'across', 100)
combined.across %>%
  mutate(sample_id = fct_relevel(sample_id, 'empirical', 'baseline')) %>%
ggplot(aes(x = IV, y = empirical_stat, 
           fill = sample_id, color = sample_id, linetype = sample_id, group = sample_id)) +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    geom_line()  +
    scale_x_continuous(breaks = c(1,2,3,4,5,6), labels = c(1,2,3,4,5,6)) +
    ylim(.4, 1) +
    ylab('cosine similarity') +
    ggtitle('divergence across pairs') +
    theme_few() +
    xlab('repetition') +
    guides(color = F, fill = F) +
    theme(aspect.ratio = 1, legend.position = c(0.5, 0.8), text = element_text(size=18), 
          element_line(size=1), element_rect(size=2, color="#00000"))
ggsave('../../writing/figs/divergence_mean.pdf', height = 10, width = 10, units = 'cm', useDingbats = F)

```

# Other figures

## Fig. 6: tsne visualizations

```{r}
tsne <- read_csv('../outputs/embeddings.csv') %>%
  left_join(d) %>%
  select(gameid, intendedName, repetitionNum, x_tsne, y_tsne, contents) %>%
  mutate(r = useful::cart2pol(x_tsne, y_tsne)$r,
         theta = useful::cart2pol(x_tsne, y_tsne)$theta) %>%
  group_by(gameid,  intendedName) %>%
  arrange(repetitionNum) %>%
  mutate(finalTheta = last(theta)) 

tsne.toplot <- tsne %>% 
  filter(intendedName == 'C') %>% 
  filter(repetitionNum %in% c(1, 6)) %>%
  filter(!is.na(x_tsne)) %>%
  group_by(gameid) %>%
  mutate(next_x = lead(x_tsne) ,
         next_y = lead(y_tsne))

ggplot(tsne.toplot, aes(x = x_tsne, y = y_tsne, color = finalTheta)) +
    geom_point(data = subset(tsne.toplot, repetitionNum == 1),
               size = 1) +
    geom_segment(aes(xend = next_x, yend = next_y), 
                 arrow.fill = NULL, 
                 arrow = arrow(length = unit(0.30,"cm"), 
                               angle = 15, 
                               type = "closed")) +
    # uncomment this line to see text labels
    # geom_text(aes(label=contents), size = 1)+
    theme_few(20) +
    scale_shape_manual(values = c(21)) +
    scale_alpha_continuous(range = c(0.5, 1))+
    scale_color_gradientn(colours = viridis(5))+
      theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank()) +
    labs(x = "", y = "") +
    guides(color = F, shape = F, alpha = F) +
    theme(aspect.ratio = 1)  #+

# make it big to zoom in on text... 
# ggsave(filename = '../../writing/figs/tsne-tangramC_enlarged.pdf',
#        width = 15, height = 15)

ggsave(filename = '../../writing/figs/tsne-tangramC.pdf',
       width = 5, height = 5)
```

## supplemental figure 11 showing all tangrams

```{r}
tsne.all <- tsne %>%
  filter(repetitionNum %in% c(1, 6)) %>%
  filter(!is.na(x_tsne)) %>%
  group_by(gameid, intendedName) %>%
  mutate(next_x = lead(x_tsne) ,
         next_y = lead(y_tsne))

ggplot(tsne.all, aes(x = x_tsne, y = y_tsne, color = finalTheta)) +
    geom_point(data = subset(tsne.all, repetitionNum == 1),
               size = 1) +
    facet_wrap(~ intendedName, nrow = 4, ncol = 3) +
    geom_segment(aes(xend = next_x, yend = next_y), arrow.fill = NULL, 
                 arrow = arrow(length=unit(0.30,"cm"), angle=15, type = "closed"), ) +
    # uncomment to see text labels
    # geom_text(aes(label=contents), size = 1)+
    theme_few(20) +
    scale_shape_manual(values = c(21)) +
    scale_alpha_continuous(range = c(0.5, 1))+
    scale_color_gradientn(colours = viridis(5))+
      theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank()) +
    labs(x = "", y = "") +
    guides(color = F, shape = F, alpha = F) +
    theme(aspect.ratio = 1) 

ggsave(filename = '../../writing/figs/tsne-alltangrams.pdf',
       width = 15, height = 15)
```

## Appendix A: Discrete analyses

How much is within-game similarity disrupted by scrambling utterances across games?

Calculate entropy under permutation tests.

Note that we explicitly do *not* normalize entropies, as this removes the contribution of a bigger vocabulary (as we would expect)

Note: this is inefficient and takes a long time to run...

```{r}
getCounts <- function(contents) {
  corpus <- Corpus(VectorSource(paste(contents, collapse = " ")))
  return(colSums(as.matrix(DocumentTermMatrix(corpus, control = list(
    removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE)))))
}

getCI <- function(vector) {
  l = length(vector)
  upper95 = ceiling(l*0.975)
  lower95 = floor(l*0.025)
  return(data.frame(list(ci_lower = sort(vector)[lower95], 
                         ci_upper = sort(vector)[upper95],
                         empirical_stat = mean(sort(vector)))))
}

permutationTest <- function(d, sample_id) {
  # scramble across games within each repetition/tangram
  permuted = d %>%
    group_by(repetitionNum, intendedName) %>%
    mutate(permutation = sample(contents)) %>%
    group_by(gameid, intendedName) %>%
    summarize(rawEntropy = entropy(getCounts(permutation)),
              l = length(getCounts(permutation)),
            normedEntropy = rawEntropy/log(l)) %>%
    group_by(intendedName) %>%
    summarize(meanEnt = mean(rawEntropy)) %>%
    mutate(sample_id = sample_id)
  return(permuted)
}

permutations <- map_dfr(seq_len(1000), ~permutationTest(d, .x)) %>%
  group_by(intendedName) %>% 
  do(., getCI(.$meanEnt)) %>% mutate(sample_id = 'permuted')

trueEntropy <- d %>%
  group_by(gameid, intendedName) %>%
  summarize(rawEntropy = entropy(getCounts(contents)), l = length(getCounts(contents)),
            normedEntropy = rawEntropy/log(l)) %>%
  group_by(intendedName) %>%
  tidyboot_mean(rawEntropy, na.rm = T) %>%
  mutate(sample_id = 'empirical') %>% 
  select(intendedName, ci_lower,ci_upper, empirical_stat, sample_id)

discrete.out <- bind_rows(permutations, trueEntropy)
```

Plotted 

```{r}
ggplot(discrete.out, aes(x = empirical_stat, y = fct_reorder(factor(intendedName), empirical_stat), 
                         color = sample_id)) +
  geom_point() +
  geom_errorbarh(aes(xmax = ci_upper, xmin = ci_lower), height = 0) +
  theme_few() +
  ylab('tangram') +
  xlab('mean entropy') +
  theme(aspect.ratio = 1/2)

ggsave('../../writing/figs/permutedDiscrete_raw.pdf', height = 8, width = 16, units = 'cm', useDingbats = F)
```

```{r}
summary(lmer(ent ~ permutation + (1 + permutation | gameid) + (1 + permutation | intendedName), 
             data = allEntropies))
```

## Appendix B: Additional baselines for evaluating divergence

we are making the claim that all people start out with something shared in how they talk about particular tangrams.
but maybe everyone is using long utterances at the beginning which makes it look similar. 
if that were true, then the actual content wouldn't matter. 
if you scrambled words across tangrams within games and recompute the averaged utterance vector, then you'd expect that permutation to be equally similar. 
instead, we find that similarity drops.


```{r}
M_mat_scrambled <- read_csv('./outputs/meta_tangrams_embeddings_scrambled0.csv', col_types = "nccnlc", na = c('[nan]')) %>%
    mutate(feature_ind = X1 + 1, # Have to correct for R's (terrible) 1-indexing...
         gameID = gameid,
         target = intendedName,
         repetition = as.numeric(repetitionNum)) 

raw_npy_names <- dir(path = './outputs/', pattern = "feats_tangrams_embeddings_rawavg_scrambled[0-9]*", full.names = T)
raw_data <- map(raw_npy_names, ~ {
   M_mat_scrambled %>% 
    group_by(target, repetition) %>%  
    do(flatten_sim_matrix(get_sim_matrix(., np$load(.x), method = 'cosine'), .$gameID)) %>% 
    ungroup() %>%
    group_by(repetition) %>%
    summarize(m = mean(sim, na.rm = T)) %>%
    mutate(sample_id = .x)
  }) %>%
  reduce(rbind)               # read all csvs and combine into single data frame

raw_data %>% group_by(repetition) %>% summarize(l = length(m), min = min(m), max = max(m)) %>% left_join(true_lmer.across %>% group_by(repetition) %>% summarize(empirical = mean(sim, na.rm = T)))
```

It appears that similarity is slightly *higher* among utterances for the same tangram across different games than for different tangrams within the same game. 

```{r}
acrossGames <- M_mat %>%
    group_by(target, repetitionNum) %>%
    do(flatten_sim_matrix(get_sim_matrix(., F_mat, method = 'cosine'),
                          .$gameid)) %>%
    filter(dim1 != dim2) %>%
  rename(gameid = dim1) %>%
    group_by(repetitionNum,gameid) %>%
  summarize(empirical_stat = mean(sim, na.rm = T)) %>% mutate(source ='across')

diffTangramWithinGames <- M_mat %>%
  group_by(gameid, repetitionNum) %>%
  do(flatten_sim_matrix(get_sim_matrix(., F_mat, method = 'cosine'),
                        .$target)) %>%
  summarize(empirical_stat = mean(sim, na.rm = T)) %>%
  filter(!is.na(empirical_stat)) %>%
  mutate(source = 'across tangrams in game') 

bind_rows(acrossGames,diffTangramWithinGames) %>%
  spread(source, empirical_stat) %>%
  mutate(diff = across - `across tangrams in game`) %>%
  group_by(repetitionNum) %>%
  tidyboot_mean(diff, na.rm = T) %>%
  ggplot(aes(x = as.character(repetitionNum), y = empirical_stat)) +
    geom_line() +
  geom_point() +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    geom_hline(yintercept = 0) +
    theme_few()
```

```{r}
unchanging_model <- lmer(diff ~ (1 |gameid), data = bind_rows(acrossGames,diffTangramWithinGames) %>%
  spread(source, empirical_stat) %>%
  mutate(diff = across - `across tangrams in game`))
mod2 <- lmer(diff ~ repetitionNum + (1 |gameid), data = bind_rows(acrossGames,diffTangramWithinGames) %>%
  spread(source, empirical_stat) %>%
  mutate(diff = across - `across tangrams in game`))
full_model <- lmer(diff ~ poly(repetitionNum,2) + (1 + repetitionNum|gameid), data = bind_rows(acrossGames,diffTangramWithinGames) %>%
  spread(source, empirical_stat) %>%
  mutate(diff = across - `across tangrams in game`))

anova(unchanging_model, mod2, full_model)
summary(full_model)

bind_rows(acrossGames,diffTangramWithinGames) %>%
  spread(source, empirical_stat) %>%
  mutate(diff = across - `across tangrams in game`) %>%
  group_by(repetitionNum) %>%
  summarize(diff = mean(diff, na.rm = T),
            across = mean(across, na.rm = T),
            `across tangrams in game` = mean(`across tangrams in game`, na.rm = T))
```
