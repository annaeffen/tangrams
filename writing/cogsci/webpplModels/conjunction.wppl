///fold:
var initList = function(n, val) {
  return repeat(n, function() {return val})
}

var uniformPs = function(vs) {
  return initList(vs.length, 1/vs.length)
}

var getTrajectories = function(data) {
  var keys = _.keys(data[0]);
  return reduce(function(key, memo) {
    var timeBasedKeys = map(function(i) {return key + "." + i}, _.range(data.length));
    var vals = _.map(data, key);
    return _.extend(_.zipObject(timeBasedKeys, vals), memo)
  }, [], keys)
};
///

var params = {
  alpha: [1],
  beta: [1],
  numSteps : [2]
};

// possible states of the world
var states = [{type: 0, color: 0}, 
              {type: 1, color: 1}];
var statePrior =  Categorical({vs: states, ps: [1/2, 1/2]});

// possible base utterances, and possible conjunctions
var unconstrainedUtterances = ['type_a', 'type_b', 'color_a','color_b'];
var derivedUtterances = ['type_a type_b', 'type_a color_a','type_a color_b',
                         'type_b color_a','type_b color_b','color_a color_b'];
var utterances = unconstrainedUtterances.concat(derivedUtterances);
var utterancePrior = Categorical({vs: utterances, ps: uniformPs(utterances)});

// takes a sample from a (biased & discretized) dirichlet distribution for each word,
// representing the extent to which that word describes each object
var lexiconPrior = Infer({method: 'enumerate'}, function(){
  var meanings = map(function(utt) {
    var aBias = utt.split('_')[1] === 'a'
    var ps = aBias ? [.3,.25,.2,.15,.1] : [.1,.15,.2,.25,.3];
    return categorical({vs: [0.01, 0.25, .5, .75, .99], ps})
  }, unconstrainedUtterances);
  return _.zipObject(unconstrainedUtterances, meanings);
});

// length-based cost
var uttCost = function(utt) {
  return utt.split(' ').length;
};

// Looks up the meaning of an utterance in a lexicon object
var uttFitness = cache(function(utt, state, lexicon) {
  return Math.log(reduce(function(subUtt, memo) {
    var relevantProperty = (subUtt.split('_')[0] === 'type' ?
                            state.type : state.color);
    var lexiconProb = relevantProperty ? lexicon[subUtt] : 1- lexicon[subUtt]
    return lexiconProb * memo;
  }, 1, utt.split(' ')));
});


// literal listener
var L0 = cache(function(utt, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var state = sample(statePrior);
    factor(uttFitness(utt, state, lexicon));
    return state;
  });
});

// pragmatic speaker
var S1 = cache(function(state, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var utt = sample(utterancePrior);
    factor(params.alpha[0] * L0(utt, lexicon).score(state)
           - params.beta[0] * uttCost(utt));
    return utt;
  });
});

// conventional listener
var L1 = cache(function(utt, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var state = sample(statePrior);
    observe(S1(state, lexicon), utt);
    return state;
  });
});

var lexiconPosterior = cache(function(originAgent, data) {
  return Infer({method: 'enumerate'}, function() {
    var lexicon = sample(lexiconPrior);
    mapData({data: data}, function(datum){
      if(originAgent === 'L') {
        observe(S1(datum.response, lexicon), datum.utt);
      } else if(originAgent === 'S') {
        observe(L1(datum.utt, lexicon), datum.response);
      }
    });
    return lexicon;
  });
});

// conventional listener (L1, marginalizing over lexicons)
var L = cache(function(utt, data) {
  return Infer({method:"enumerate"}, function(){
    var lexicon = sample(lexiconPosterior('L', data));
    var state = sample(L1(utt, lexicon));
    return state;
  });
});

// conventional speaker (S1, reasoning about expected listener across lexicons)
var S = cache(function(state, data) {
  return Infer({method:"enumerate"}, function(){
    var utt = sample(utterancePrior);
    var utility = expectation(Infer({method: 'enumerate'}, function() {
      var lexicon = sample(lexiconPosterior('S', data));
      return (params.alpha[0] * L1(utt, lexicon).score(state) -
	      params.beta[0] * uttCost(utt));
    }));
//    console.log(utt);
//    console.log(utility);
    factor(utility);
    return utt;
  });
});

var model = function() {
  var step = function(data) {
    if(data.length > params.numSteps[0]) return getTrajectories(data);
    var state = states[0];
    var utt = sample(S(state, data));
    var response = sample(L(utt, data));
    var newDatum = {utt, response, intended: state, acc: state == response};
    return step(data.concat(newDatum));
  };
  step([]);
};

// console.log(L('type_a color_a', []))
// console.log(L('type_a', []));
// console.log(L('color_a', []));

//S(states[0], []);
