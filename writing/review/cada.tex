\documentclass[11pt, floatsintext, jou]{apa6}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage[outdir=./]{epstopdf}
\usepackage{etoolbox}
\patchcmd{\maketitle}{\newpage}{}{}{}

%\DeclareGraphicsExtensions{.eps}

\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{apacite}
\usepackage{listings}
\usepackage{multirow}
\usepackage{todonotes}
\usepackage{svg}
\usepackage{booktabs}
\usepackage{afterpage}

\newcommand{\den}[2][]{
\(
\left\llbracket\;\text{#2}\;\right\rrbracket^{#1}
\)
}


\newcommand{\KL}[2]{\ensuremath{D_{KL}({#1}\, \| \, {#2})}}
\newcommand{\E}[2]{\ensuremath{\mathbb{E}_{#1}\left [#2 \right]}}

\newenvironment{figurehere}
	{\def\@captype{figure}}
	{}

\setcounter{tocdepth}{2}
\usepackage{lipsum}
%\pagenumbering{gobble}
%\usepackage{apacite}

%\linespread{1}
\usepackage{textcomp}
\usepackage{lingmacros}
\usepackage{setspace}%\doublespacing 

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\graphicspath{{./figures/}}
 
\makeatother

\title{Convention formation and hierarchical learning \\ in repeated communication}
\shorttitle{CADA}
\author{Robert Hawkins}
\affiliation{Stanford University} 

\abstract{}

%\keywords{conventions, pragmatics, semantics, adaptation, learning hierarchical Bayesian models}

%\authornote{This report is based in part on work presented at the 37th Conference of the Cognitive Science Society. The first author is supported by a NSF Graduate Research Fellowship and a Stanford Graduate Fellowship. Correspondence concerning this article should be addressed to Robert X.D. Hawkins, e-mail: rxdh@stanford.edu}

\begin{document}

\maketitle
%\tableofcontents

\section{Introduction}%: Core competencies for adaptation in communication}

We do not have to learn language from scratch with every new person we meet. A native of Chicago can try out a coffee shop in San Francisco without needing to laboriously work out with the barista a brand-new way of ordering an `espresso,' and a 21st century reader can largely make sense of a 19th century novel without any personal contact with its author. This degree of stability across geography and time makes language indispensable for coordination in a social species: everyone who belongs to a language community assumes that others will share at least some common beliefs, or \emph{global conventions}, about what words mean \cite{Lewis69_Convention}. In a sense, the ability to competently generalize to novel communicative partners in novel contexts is what it means to be fluent in a language.

At the same time, no two speakers of a language share exactly the same lexicon, and to make matters worse, speakers seem to constantly come up with new expressions and senses on the fly \cite{Davidson86_DerangementOfEpitaphs, Clark98_CommunalLexicons}. This lexical diversity quickly becomes apparent at another family's dinner table, or when moving to a new work environment. Large stretches of conversation become borderline unintelligible. Who is this mysterious ``Tom'' everyone is laughing about? What do these arcane acronyms mean? Yet they do not remain mysterious for long. Across repeated interactions with a particular partner or group or partners, we build up intricate, idiosyncratic models: not just about how \emph{we} collectively use language, but how \emph{this person} is expected to use language. We learn the contours of their speech and form \emph{local conventions} from our shared history. Complex stories or ideas that took long discursive conversations to initially cover can be referred back to using a brief turn of phrase. Most strikingly, this adaptation can take place to different degrees over any time-scale: from years of close scientific collaboration to a few minutes in a doctor's office.

A core puzzle for cognitive science, then, is reconciling our remarkable flexibility in adapting to novel communication partners with the overarching stability of our linguistic representations. What do we do when our global conventions aren't sufficient --- when we have to talk about something we've never had to talk about before with a partner we've never met? How do we adapt and coordinate so quickly? And how do we determine which learned meanings we can expect to stably generalize to new contexts or partners, and which only hold in the narrow scope of one partner?

Any computational theory of flexibility and adaptation in communication must therefore explain both how we use our mature global conventions to scaffold local convention formation, and also where our global conventions came from in the first place. The puzzle of adaptation can be parsed into three component challenges that any solution must adequately address:
\begin{enumerate}
\item \textbf{Lexical priors:} When we first encounter a new communication partner in a new context, we call upon some representation about what we think different signals mean to them. This representation of meaning must be sensitive to the overall statistics of the population: more people are familiar with the use of \emph{dog} to refer to the beloved pet than \emph{sclerotic aorta} to refer to the potentially dangerous health condition. It must also be sensitive to the immediate context of the interaction: a cardiologist should have different expectations about a novel colleague than a novel patient.
\item \textbf{Rapid lexical learning:} Within a few minutes of conversation, we can considerably strengthen our expectations about our partner's lexicon based on earlier utterances and feedback, and adjust our own usage accordingly. For example, even if we are not initially familiar with the term \emph{sclerotic aorta}, a few minutes spent discussing the condition in simpler terms should make us more confident using the term with that partner in the future. This social learning mechanism must allow for signal \emph{reduction} -- simpler, more efficient ways of referring to the same thing over time -- and \emph{path-dependence}: early reinforcement of certain meanings increases their later usage, however arbitrary or provisional they began. 
\item \textbf{Generalization:} When we encounter the same partner in a new context, we should expect some `stickiness' from previous learning. Language does not reset at context boundaries. In addition, the lexical model we've learned within a conversation should be largely \emph{partner-specific}. Just because we now expect Partner A to be familiar with a \emph{sclerotic aorta} shouldn't radically change our expectations about Partner B. Over enough interactions with different language users, however, our initial representations should be able to shift to take these data into account. To generalize appropriately, we must be able to correctly attribute whether a usage is idiosyncratic to a particular speaker, or a global convention we should expect to hold across the whole community.

\end{enumerate}

\subsection{Modeling convention formation as hierarchical Bayesian learning}

We begin by proposing a hierarchical Bayesian model of convention formation \cite{GelmanEtAl14_BDA,TenenbaumKempGriffithsGoodman11_Grow_a_Mind_Science} that provides a useful mathematical and conceptual framework for addressing these challenges. Hierarchical models have been key to explaining how the human mind solves difficult inductive problems in domain like causal learning \cite{KempGoodmanTenenbaum10_LearningToLearn,GoodmanUllmanTenenbaum11_TheoryOfCausality} and concept learning \cite{KempPerforsTenenbaum07_HBM} where abstract, shared properties must be jointly inferred with idiosyncratic particulars of instances. Unlike the fixed, biological concept of a dog, though, language is a moving target. The only data we use to ground our learning is produced by other agents who are in the same position as we are, and our only goal is to coordinate on the same meanings in context \cite{HassonGhazanfar___Keysers12BrainToBrain}. This is the sense in which the meanings we learn are conventional. This \emph{social grounding} is precisely what gives rise to the fascinating idiosyncracies of local convention formation.

We begin by defining a lexicon as a function $$\mathcal{L}_i: (w, o) \rightarrow [0,1]$$ assigning any word-object pair a real-valued meaning in the unit interval \cite{GrafEtAl16_BasicLevel}. There are \emph{many} potential ways this function could be represented in the mind at the algorithmic level. It could be derived from a store of exemplars, a set of independent prototypes for each word, a neural network embedding words and objects in a vector space, and so on \cite<see>[for a recent review of candidates]{JonesEtAl15_SemanticMemory}. 

Just as our concept of a dog, built up over many individual experiences across a lifetime, provides stable expectations about the properties of a new instance -- four legs, wagging tail, barking noises -- our accumulated lexical knowledge provides stable communicative expectations. 
This knowledge is represented by a `overhypothesis' or shared lexical representation $\Theta_0$, which parameterizes the prior expectations about any individual partner's lexicon: $P(\mathcal{L}_i | \Theta_0)$. 

For the conceptual purposes of this paper, it is not important exactly what form this distribution takes, or what initial prior over the overhypothesis $P(\Theta_0)$ could in principle guide early language learning
\footnote{
For simplicity, we could assume $\Theta_0$ is an $\mathcal{W} \times \mathcal{O} \times 2$ tensor containing values $(\alpha_{(w,o)}, \beta_{(w,o)})$ for every entry $(w,o)$ in the lexicon $\mathcal{L}_i$. This would factor the lexical prior $P(\mathcal{L}_i | \Theta_0)$ into independent Beta distributions over intervals $[0,1]$. It would then be straightforward to place an uninformative prior $P(\Theta_0)$ over that tensor which does not overwhelm the likelihood \cite<see>[p. 110, for some reasonable choices]{GelmanEtAl14_BDA}. More generally, we could allow for arbitrarily complex dependencies between entries of the lexicon by using a Bayesian neural network with weight tensor $\Theta_0$.% that takes word-object pairs $(w,o)$ as input. 
}. It only matters that this knowledge is hierarchical: we expect all members of our language community to share some commonality in what they mean by things. 

Now that we have defined a hierarchical likelihood on lexical beliefs, we must say how we \emph{learn} partner-specific models. Just as years of living with your beloved Fido reveals properties which deviate from your general dog concept -- patches of hair missing from his legs, an odd squeaking noise he makes when excited -- the language we use to talk with a family member or close collaborator may deviate considerably from the usage predicted by global conventions. In other words, our beliefs about a particular partner's lexicon $\mathcal{L}_i$ are formed by integrating our abstract lexical knowledge $\Theta_0$ with particular  observations $D_i$ of that particular individual:
$$%\begin{array}{rcl}
P(\mathcal{L}_i | D_i)  \propto \int_{\Theta_0}P(\mathcal{L}_i | D_i,  \Theta_0) P(\Theta_0 | D_i) 
%                     & = & \mathbb{E}_{\Theta_0}[P(\mathcal{L}_i | \Theta_0, D_i)] 
%\end{array}
$$
where the posteriors in the integral can be computed using Bayes rule:
$$
P(\mathcal{L}_i | D_i, \Theta_0) \propto P(D_i | \mathcal{L}_i, \Theta_0) P(\mathcal{L}_i | \Theta_0)
$$
While this holds when we only have observations from a single speaker, note that our posterior beliefs about $\Theta_0$ are in fact informed by observations from \emph{all} speakers: $D = \bigcup_{i=1}^k D_i$. For  adult language users who have observed innumerable uses of language over their lifetimes, the contribution of a new data point to the overhypothesis $P(\Theta_0 | D)$ should be negligible; the contribution to a partner-specific model, however, can be quite strong. 

Finally, to fully specify our model and compute our partner-specific lexical posterior $P(\mathcal{L}_i, D_i, \Theta_0)$, we must link our beliefs about a partner's lexica to their actual behavior with a likelihood function $P(D_i | \mathcal{L}_i, \Theta_0)$. This is naturally supplied by the Rational Speech Act framework \cite{FrankGoodman12_PragmaticReasoningLanguageGames,GoodmanFrank16_RSATiCS,BergenLevyGoodman16_LexicalUncertainty,SmithGoodmanFrank13_RecursivePragmaticReasoningNIPS}: we assume speakers produce utterances that are parsimonious yet informative in context with respect to their lexicon, and listeners interpret utterances by inverting a speaker model. Because we expect our partner to use language rationally given some lexicon, the utterance they choose to refer to some object will be probable under some lexica and highly improbable under others. In this way, a particular agent's language use is a cue to their particular lexicon. We omit mathematical details here due to the conceptual nature of the article, but a full account of the non-hierarchical version of this model can be found in \citeA{HawkinsFrankGoodman17_ConventionFormation}.

In summary, our hierarchical model formalizes the intuition that global conventions are learned and generalized over many extended interactions with many different people across a lifetime, and that this shared semantic prototype is the backbone supporting rapid learning for new partners and situations. 

\subsection{Convention formation in the lab}

\begin{figure*}[t!]
\centering
\includegraphics[scale=.5]{task_cropped.pdf}
\caption{Generic setup for repeated reference game task in the lab using stimuli from Wilkes-Gibbs \& Clark (1986); on every round, the speaker refers to each target in some context, and the listener attempts to pick out the intended referent. Both players are free to speak at any time.}
\label{fig:example}
\end{figure*}

In the remainder of this paper, we consider the empirical evidence for each of our three core competencies, reinterpret these phenomena in light of our hierarchical model, and discuss its broader implications. Though more wide-ranging sources of data could potentially be relevant, we restrict our present scope to a family of interactive communication experiments called \emph{repeated reference games}. These games provide a natural and  productive paradigm for studying lexical adaptation in the lab. 

In their simplest design (see Fig. \ref{fig:example}), pairs of participants are shown arrays of objects, presented in randomized order. On each round of the game, one player -- the speaker -- must produce a message allowing their partner to select a given target from the context. By fixing a closed set of referents and a clear communicative goal in common ground, these games vastly simplify the tangle of real-world communicative behavior. At the same time, by allowing real social partners to freely interact using natural language, we avoid the hazards of artificial or confederate-based language tasks \cite{KuhlenBrennan13_LanguageInDialogue} and expose the rich dynamics of language use in context. Given the current state of the field, then, reference games are arguably an ideal compromise between analytic tractability and ecological validity. 

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table*}[h]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{}                                   & \textbf{Parameter}                                              & \multicolumn{1}{l}{\textbf{Example parameter settings}}                 \\ \midrule
\multirow{11}{*}{\textbf{Partner design}}    & \multirow{3}{*}{What feedback is provided?}                & - no feedback at all                                                  \\
                                            &                                                                 & - only correct/incorrect                                                   \\
                                            &                                                                 & - real-time responses from partner                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{Are you playing with the same partner?}         & - same partner for whole game                                              \\
                                            &                                                                 & - swap out partners every round                                            \\
                                            &                                                                 & - swap after $k$ rounds                                                    \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{What do you know about your partner?}         & - anonymous stranger                                              \\
                                            &                                                                 & - stranger with perceptual information                                            \\
                                            &                                                                 & - close friend                                                    \\ \cmidrule(l){2-3}                                             
                                            & \multirow{2}{*}{How consistent are roles across repetitions?}   & - consistent director/matcher                                              \\
                                            &                                                                 & - alternate roles each round                                               \\ \midrule
\multirow{7}{*}{\textbf{Stimulus design}}   & \multirow{2}{*}{How familiar are targets?}                      & - very familiar: colors, household objects                                 \\
                                            &                                                                 & - not at all familiar: tangrams, novel line drawings                       \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How complex are targets?}                       & - very complex: busy visual scenes, clips of music                         \\
                                            &                                                                 & - not at all complex: geometric drawings                                   \\ \cmidrule(l){2-3} 
                                            & \multirow{3}{*}{How consistent are targets across repetitions?} & - exact same image of object                                               \\
                                            &                                                                 & - different pose/view of same object                                       \\
                                            &                                                                 & - different objects from same neighborhood                                 \\ \midrule
\multirow{5}{*}{\textbf{Context design}}    & \multirow{2}{*}{How similar are distractors to the target?}     & - very similar: same basic-level category                                  \\
                                            &                                                                 & - not at all similar: other categories                                     \\ \cmidrule(l){2-3} 
                                            & What is the size of context?                                    & - between 2 and 21                                                         \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{How consistent is context across repetitions?}  & - exact same context each round                                            \\
                                            &                                                                 & - randomized context (sometimes far, sometimes close)                      \\ \midrule
\multirow{3}{*}{\textbf{Repetition design}} & How many repetitions per target?                                & - between 3 and 100                                                        \\ \cmidrule(l){2-3} 
                                            & \multirow{2}{*}{What is spacing between repetitions?}           & - block structure                                                          \\
                                            &                                                                 & - sequential structure with interspersed contexts                          \\ \midrule
\textbf{Modality design}                    & What medium is used for communication?                          & \begin{tabular}[c]{@{}l@{}}- text\\ - audio\\ - gesture\\ - drawing\end{tabular} \\ \bottomrule
\end{tabular}%
}
\caption{\normalfont{Proposed parameterization for repeated reference games, each of which theoretically impacts the formation of conventions.}}
\label{table:parameters}
\end{table*}

While one-shot reference games, which manipulate context, have been instrumental in revealing systematic pragmatic effects in the referring expressions people tend to generate \cite{KraussWeinheimer67_ReferentSimilarity,KoolenGattGoudbeekKrahmer11_Overspecification,GrafEtAl16_BasicLevel,VanDeemter16_ComputationalModelsOfReferring}, a range of even richer phenomena begin to emerge when the communication task is \emph{repeated} and the same target must be referred to multiple times. Since \citeA{KraussWeinheimer64_ReferencePhrases} first attempted such a design, many variations on this basic setup have been designed to test the boundaries of adaptation, manipulating the kinds of objects used as targets, the contexts in which the objects appear, the identity of one's partner across repetitions, the feedback available, and the medium participants use to communicate. In Table \ref{table:parameters}, we propose a potential parameterization of this family of repeated reference games, suggesting a set of conditions controlling when conventions may form. We organize our review of this literature along the three core challenges observed earlier, which roughly correspond to the temporal structure of repeated reference games. In experimental terms: What influences the content of initial messages, how do these messages change over the coarse of the game, and under what conditions do these changes transfer to other scenarios?   %  In Table \ref{table:experiments}, we summarize 

\todo[inline]{Provide another table summarizing a bunch of studies? Or add a column to Table 1?}

%This review is  organized around a meta-analytic parameterization of the paradigm (see Table 1), highlighting several properties of the task that appear to affect the rate at which conventions form. We then briefly contrast our hierarchical model with several different theories of adaptation and convention formation. 

\section{Lexical priors}

People know a lot of words \cite{BergelsonAslin17_Lexicon}. Exactly how flexible knowledge about words and their meanings is structured and accessed in one's own ``mental lexicon'' remains a significant open question in cognitive science \cite{JonesEtAl15_SemanticMemory,GriffithsSteyversTenenbaum07_Topics,HuthEtAl16_SemanticMaps,GoodmanLassiter14_Semantics}. For the purpose of communicating with another speaker, however, a more relevant question is what lexicon we think our \emph{partner} is using. In this section, we review evidence from the initial rounds of repeated reference games that these lexical expectations are \emph{probabilistic} and \emph{context-sensitive}, thus providing a basis for interpreting expectations about a novel partner's lexicon as a probabilistic prior $P(\mathcal{L}_i | \Theta_0)$. 

%While a full review of ``audience design'' in generating referring expressions is outside the scope of this paper, a handful of results are directly relevant for understanding the initial lexical priors that participants bring to bear in repeated games. 

\subsection{Uncertainty in lexical expectations}

While it is convenient to view the lexicon as fixed knowledge  \cite{Cruse86_LexicalSemantics,Pinker95_LanguageInstinct,FrankGoodman12_PragmaticReasoningLanguageGames}, meanings are in reality quite flexible and ad hoc \cite{Clark83_NonceSense,ClarkGerrig83_OldWordsNewMeanings,ClarkClark79_NounsSurfaceAsVerbs,GerrigBortfeld99_SenseCreation,LascaridesCopestake98_PragmaticsWordMeaning,Glucksberg01_FigurativeLanguage,LassiterGoodman15_AdjectivalVagueness}. 
Correspondingly, recent computational models have explored the possibility that we instead represent semantic \emph{uncertainty} over which meanings our partner might intend \cite<e.g.>{CooperEtAl15_ProbabilisticTypeTheory,BergenLevyGoodman16_LexicalUncertainty,SmithGoodmanFrank13_RecursivePragmaticReasoningNIPS,PottsEtAl16_EmbeddedImplicatures,HawkinsFrankGoodman17_ConventionFormation}. 
This uncertainty leaves its signature on the initial round of repeated references games, when speakers are attempting to produce descriptions of potentially ambiguous objects for a novel partner.

In one direct demonstration, \citeA{FussellKrauss89_IntendedAudienceCommonGround} asked forty students to produce referring expressions for abstract line drawings in a repeated reference game set-up. Instead of proceeding to play the game in person, however, participants were told that their messages were intended for later identification \cite<see>[for earlier variations on this design]{KraussEtAl68_InnerSpeech, Danks70_EncodingCommunication, Innes76_InnerExternal}. Half the participants were told that these messages were intended for \emph{themselves} in the future (the `non-social' or `familiar listener' condition) while the other half were told that an anonymous other would see them (the `social' or `unfamiliar listener' condition). 

Because both groups were faced with the same communicative task, this manipulation provided some evidence about how lexical expectations differ depending on the listener. If participants used the same fixed meaning when reasoning about themselves and others, we would expect similar messages. Instead, utterances intended for others were more than twice as long as utterances for oneself (12.7 vs. 5.0 words). Furthermore, these social expectations supported effective communication: when participants were brought back into the lab 3-6 weeks later to perform a 30-way identification task given these previously collected descriptions, they performed best given their own (86\% accuracy) but when presented with others participants' descriptions, they did significantly better when those descriptions were explicitly designed for an unfamiliar listener (60\% vs. 49\%). 

Why produce longer utterances for others? A key empirical observation is that similar self-other length effects were found by \citeA{Innes76_InnerExternal} using ambiguous stimuli like abstract designs, inkblots, and poems, but \emph{not} by \citeA{KraussEtAl68_InnerSpeech} where the same procedure was conducted with familiar color chips. \cite{HupetEtAl91_CodabilityReference} make this comparison explicitly by independently norming the `codability' of a large array of tangrams: One parsimonious explanation is that in contexts where global conventions are stronger and lexical uncertainty is lower (e.g. for common colors), speakers expect others to share identical lexical beliefs and can get away with similarly terse descriptions for self and other. Meanwhile, for ambiguous stimuli like inkblots or tangrams that speakers have had limited experience communicating about, they have substantial uncertainty about how an anonymous other, drawn from their global prior, will interpret their words. %For instance, in the scenario shown in Fig. \ref{fig:example}, the target may look very clearly like an ice skater to the speaker, so they may be confident that their future self will interpret the short label ``ice skater'' consistently, but also recognize that since your partner has had no experimen  
It could therefore be worth spending a few additional words to provide clarifying information, saying ``the upside-down martini glass in a wire stand'' instead of just ``the martini'' \citeA{HawkinsFrankGoodman17_ConventionFormation}.  %even if the latter would be sufficient to remind yourself of your own experience.
%\citeA{HawkinsFrankGoodman17_ConventionFormation} showed in simulations that a compositional variant of the Bayesian speaker model discussed earlier makes this prediction: longer messages are preferred under increased uncertainty over the lexicon. 

\todo[inline]{Discuss Hupet et al, 1991 results that initial descriptions depend on `codability' and `discriminability' of stimuli in context, e.g. that there is substantial arbitrariness for some and not others\dots}

This explanation is also consistent with broader linguistic phenomena outside the realm of repeated reference games. For example, \citeA{PottsLevy15_Or} showed that lexical uncertainty is critical for capturing constructions like \emph{oenophile or wine lover}, where a disjunction of synonymous terms is taken to convey a definition -- information about the lexicon -- rather than a disjoint set. While the reasons that speakers produce such constructions are surely more complex, we suggests the further conjecture that speakers are more likely to produce this definitional \emph{or} when the component word is rarer or more obscure: when there is additional uncertainty over its likely meaning in the listener's lexicon. 

\subsection{Context-sensitivity in lexical expectations}

%llow for graded uncertainty in our lexical expectations, how do these expectations differ for particular novel speakers in particular contexts? 
A global lexical prior $P(\mathcal{L}_i | \Theta)$ is an excellent guide to what meanings an anonymous member of our language might have. Yet we typically know a thing or two about a novel conversation partner before we start talking to them --- their perceived age, gender, dress, social role, any behavior we've witnessed \cite{Davidson86_DerangementOfEpitaphs,KleinschmidtJaeger15_RobustSpeechPerception}. Our prior should be flexible enough to take this evidence into account. Repeated reference games in the lab usually take care to disguise as much of this evidence as possible, though some properties of the sample are unavoidable: when recruited on a college campus, participants can safely assume their partner is another student, for instance. 

In one study, \citeA{FussellKrauss92_JPSP} tested the extent to which lexical priors are well-calibrated to minimal expectations of cultural knowledge in the target population. In a repeated reference game using faces of public figures like Woody Allen and Ronald Reagan, they found that speakers gave lengthier initial descriptions for figures who were expected to be less identifiable or well-known, as estimated from independently elicited priors. This relationship held when restricted to messages containing correct names, meaning that speakers who themselves knew the identity of the figure were nonetheless more likely to add additional information to their initial description when they expected a typical partner not to know. 

\citeA{FussellKrauss92_JPSP} also predicted that additional information about the \emph{gender} of partners would be incorporated into lexical expectations. In particular, they expected that because men and women stereotypically have some gendered lexical expertise (e.g. men know more names for car parts), participants would be more likely to provide additional information to the opposite gender. They again found an effect of overall expected familiarity, but did not find an interaction with gender, musing that the perceived discrepancy was perhaps too small to detect in the items used.

It is natural to view the self and the stranger as points on a continuum, with stronger initial expectations for close friends or family with whom we have a long history of interaction and potentially weaker expectations for children, non-native speakers, or out-group members. This first prediction was tested by \citeA{FussellKrauss89_FriendsAndStrangers} who brought self-identified pairs of friends into the lab and had them individually produce descriptions such that `their friend' could identify it. They failed to find a significant difference in description length from the descriptions produced for strangers in \citeA{FussellKrauss89_IntendedAudienceCommonGround}, but this negative result is somewhat hard to interpret for two main reasons acknowledged by the authors. First, their interpretation of `friendship' was not well-controlled and many pairs were only casual acquaintances drawn from the same college population as the `other student' that participants in the `stranger' condition were instructed to produce descriptions for. Second, even with deep knowledge of an intimate partner's lexicon, it is not clear how relevant this knowledge would describing for a set of abstract line figures: it was specifically designed to be novel and somewhat unnatural. 

\begin{figure}[t]
\includegraphics[scale=0.85]{reduction.pdf}
\caption{Reduction in message length under a variety of conditions. Message length is measured as the mean Fifteen repeated reference game experiments. }
\label{fig:reduction}
\end{figure}


Despite these underwhelming early results, the context-sensitivity of lexical priors remains a tantalizing area to revisit. In particular, more recently developed methods for measuring subjective beliefs and expectations \cite<e.g.>{FrankeEtAl16_CrowdBelieve, DelaneyBuschEtAl17_Cogsci} could provide much more direct access to underlying lexical beliefs, and large-scale online experiments could more systematically uncover the underlying structure of social group representations along which lexical expectations are organized. 

\section{Rapid lexical learning}

If our lexical priors -- our global conventions -- serve as a source of stability in meaning over longer timescales, then what accounts for our extraordinary flexibility  over short timescales? How do we coordinate on efficient local conventions, or \emph{conceptual pacts}, for talking about things we've never talked about before? In this section, we review the dynamics of coordination within repeated reference games and explore the possibility that rapid adaptation can be understood in our hierarchical Bayesian modeling framework as lexical inference given partner-specific data: $P(\mathcal{L}_i | D_i, \Theta)$. 

\subsection{Convergence on efficient conventions}

The most well-known phenomenon in repeated reference games is a reduction in message length over multiple rounds. \citeA{KraussWeinheimer64_ReferencePhrases} were the first to report this phenomenon in a short technical report introducing the repeated reference game paradigm, and it has been replicated many times under many conditions \cite<most notably by>[in a much more streamlined experimental design using tangram shapes]{ClarkWilkesGibbs86_ReferringCollaborative}. Out of historical interest, it is worth describing the original design in detail. 

Both players were given an identical set of 6 cards marked randomly with 1-6 and A-F, respectively, containing the same 6 drawings in different orders. The pair's goal was to figure out the correspondences between their 6 cards by talking about the locations of the images. In each set, three images were `redundant,' appearing in the same location on every card---discussing these was not very useful for the task---while the other three were `diagnostic' and necessarily had to be referred to. This design therefore had the peculiar property that different drawings appear with different frequencies: some objects were referred to nearly 100 times (e.g. if diagnostic for every set of cards across all 16 rounds) and others only a handful of times. 

Their core descriptive result was that, taken in aggregate, frequently mentioned targets tend to be labeled using shorter phrases than infrequently mentioned targets, thus reproducing Zipf's law within the microcosm of a single conversation. To explain the process by which such a distribution emerges, they reasoned that labels may change with repeated use over the course of interaction. Indeed, the first time participants referred to a figure, they used a lengthy, detailed description (``the upside-down martini glass in a wire stand'') but with a small number of repetitions -- between 3 to 6 times, depending on the pair -- the description was reduced down to the limit of just one or two words (``martini''). 

%Rather than talking about slabs and bricks, as Wittgenstein's builders did, these participants were presented with an array of abstract line drawings. %This design was somewhat convoluted compared to later studies refining the paradigm but it's worth considering in detail, as it's the prototype from which all later studies derived.

% The most significant conceptual replication of this effect was conducted by . This streamlined version honed in on the process of social reasoning that allowed partners to successfully use short labels by the end. In their version of the task, participants were given boards containing the same 12 abstract tangrams (see Fig. 1b for a subset) but in scrambled orders. One participant -- the ``director'' -- was assigned to move sequentially through the grid, describing each one so that the other player -- the ``matcher'' -- can rearrange their tangrams to match. Critically, once the pair reached consensus and received feedback about mismatches, their tangrams are re-scrambled and they repeat the task for a total of 6 rounds. Thus, each of the 12 objects were referred to exactly 6 times. 

Note that although initial messages are just as long or longer than the other-intended messages collected by \citeA{FussellKrauss89_IntendedAudienceCommonGround}, final messages are as short or shorter than the one-shot messages intended for \emph{oneself}. Furthermore, final messages are often incomprehensible to overhearers who were not present for the initial messages \cite{SchoberClark89_Overhearers}. This observation sets up the central empirical puzzle of convention formation: how does a short word or phrase that would have been completely ineffective for communicating under the initial lexical prior become perfectly understandable over mere minutes of interaction? What changes inside participants' minds in the interim? 

One simple non-social explanation --- that reduction is merely an effect of familiarity or repetition on the part of the speaker --- can be easily dispelled. When participants are asked to repeatedly refer to the same targets for a hypothetical partner, no reduction is found, and in some cases utterances actually get longer \cite{HupetChantraine92_CollaborationOrRepitition}. Whatever is changing must be a result of the \emph{interaction} between partners. An alternative explanation suggested by our probabilistic model is that reduction is driven by lexical learning as communication partners coordinate on ad hoc names. If long initial messages can be explained as the result of initial uncertainty in the lexical prior, as discussed in the previous section, then a decrease in uncertainty licenses shorter messages \cite{HawkinsFrankGoodman17_ConventionFormation}. 

What are empirical cues to this reduction in uncertainty? The first is the use of \emph{hedges}. Hedges are expressions like \emph{sort of} or \emph{like}, and morphemes like \emph{-ish}, that explicitly mark uncertainty or provisionality, such as \emph{a car, sort of silvery purple colored} \cite{BrennanClark96_ConceptualPactsConversation,Fraser10_Hedging,MedlockBriscoe07_HedgeClassification}. If participants reduce their lexical uncertainty over successive rounds, then we might expect a corresponding decrease in explicit markers of this uncertainty. \citeA{BrennanClark96_ConceptualPactsConversation} counted hedges over four repetitions of an initially ambiguous target and found widespread use of \emph{hedges} on the first round (occurring 26\% of messages) but almost complete absence on the last (only 2\% of messages). They also found very few initial hedges for targets with low initial uncertainty (e.g. a shoe in the context of dogs and fish), providing additional evidence for the role of \emph{lexical} uncertainty as opposed to a generic social use of hedges.

Another characteristic of uncertainty reduction lies in \emph{what} gets reduced. Is the speaker adopting a fragment shorthand by randomly dropping function words, or are they simplifying or narrowing their descriptions to names by omitting redundant details? Closed-class parts of speech like determiners and prepositions \emph{are} much more likely to be dropped than open-class parts of speech like adjectives and nouns. But when we examine broader grammatical units using recent NLP techniques, we find that entire modifying clauses are increasingly likely to be dropped \cite{HawkinsFrankGoodman17_ConventionFormation}. This accords with early hand-tagged analyses by \citeA{Carroll80_NamingHedges}, which found that in three-quarters of transcripts from \citeA{KraussWeinheimer64_ReferencePhrases} the short names that participants converged upon were prominent in some syntactic construction at the beginning, often as a head noun that was initially modified or qualified by other information. 

These more fine-grained analyses suggest that reduction is grounded in the prior lexical content of the interaction and the speaker's increasing confidence in how the listener will interpret an initially ambiguous label. Like the evidence we reviewed about lexical priors, however, this evidence remains indirect and raises the need for more careful, direct measurement of lexical uncertainty over interaction. 

\subsection{Quality of feedback}

If adaptation is learning, then the extent to which partners adapt should depend critically on the quality of the data $D_i$ on which they are conditioning: $P(\mathcal{L}_i | \Theta, D_i)$. In the absence of additional cues to the meanings that their partner is using to interpret their messages, a speaker or drawer can only continue to rely on their prior, or indeed elaborate upon it. A common feature of the reference games reviewed so far is the capacity for \emph{real-time feedback channel}: either player may say anything at any point in time, thus allowing for interruptions, back-channel responses (uh-huh, hmmm, huh?), clarification questions, and so on. To what extent is this design choice necessary for reduction? \citeA{KraussWeinheimer66_Tangrams} were the earliest to address this question by manipulating the kind of feedback received by the speaker.

% In one condition, participants were able to talk freely and bidirectionally as in \citeA{KraussWeinheimer64_ReferencePhrases}; in another condition, the channel was unidirectional: the speaker was unable to hear the listener's responses. This real-time feedback manipulation was crossed with a behavioral feedback manipulation where the experimenters intercepted the listener's responses: one group of speakers was told that their partner made the correct response 100\% of the trials (regardless of their real responses), while another was told on half of the trials that their partner made the incorrect response. 

Intuitively, we might expect that if the speaker is unsure how their longer descriptions are being interpreted -- unsure whether or not they can get away with shorter, more ambiguous expressions -- they may not have enough evidence about meanings to justify shorter utterances. Indeed, \citeA{KraussWeinheimer66_Tangrams} found that even when told that their partner was getting 100\% correct, entirely blocking the verbal feedback channel significantly limited the reduction effect. Speakers converged to utterances that were about twice as long -- twice as inefficient -- in the limit. Telling speakers that their partner was performing poorly also inhibited reduction as a main effect, though to a lesser extent. In the extreme case of trying to communicate to a listener who can't respond and appears to not understand, speaker utterance length actually increased with repetition after an early dip. \citeA{HupetChantraine92_CollaborationOrRepitition} later found that in the \emph{complete} absence of feedback --- when the speaker is instructed to repeatedly refer to a set of objects for a listener who is not present and will do their half of the task offline --- there is also no reduction in message length.

More graded disruptions of feedback seem to force the speaker to use more words overall but not to significantly change the rate of reduction (though rigorous comparisons between rates have not been conducted). For example, \citeA{KraussBricker67_Delay} tested a transmission delay to temporally shift feedback and an access delay to block the onset of listener feedback until the speaker is finished. Later, \citeA{KraussEtAl77_AudioVisualBackChannel} replicated the adverse effect of delay but showed that undelayed visual access to one's partner cancelled out the effect and returned the number of words used to baseline. 

Some access to minimal feedback from one's partner therefore appears to be a necessary condition for convention formation. Without it, there is no reliable cue to the partner's lexicon; no lexical learning can take place, and consequently no social coordination. Yet this condition alone doesn't explain the \emph{speed} with which partners adapt, approaching `one-shot' learning. Three additional factors seem relevant. 

First, like other scenarios of rapid learning from sparse data, abstract prior knowledge is crucial \cite{TenenbaumKempGriffithsGoodman11_Grow_a_Mind_Science,LakeEtAl16_BuildingMachines}: agents do not start from scratch, they must only fine-tune their pre-existing global conventions to fit their immediate partner and context. Second, agents have pragmatics on their side. In the RSA model linking lexical knowledge to behavior, listeners assume their partner is attempting to be \emph{informative} and pragmatic speakers, in turn, \emph{expect} listeners to do so. These assumptions dramatically strengthen feedback. Because listeners reason about alternatives -- that the speaker \emph{would} have used another word or description if it described the target better in context -- both agents actually learn about the meanings of words that were not uttered\footnote{
This is the \emph{lateral-inhibition} dynamic described at length by \citeA{Steels03_GroundedCommunication,SteelsEtAl05_CoordinatingColors,Steels15_TalkingHeadsExperiment}, which emerges naturally in our model from basic Gricean principles.
}. Similarly, the existence of a listener backchannel (knowing a listener \emph{would} object or ask for clarification if their lexicon differed) implies evidence for the utterance's meaning in the absence of such objections. A third factor is the sociolinguistic information derived from social group inferences, which are often tightly controlled in lab settings but likely more relevant in the real world. 

\subsection{Social group inference}

In addition to updating our model of a particular partner based on immediate feedback, i.e. utterances and choices made in previous rounds of the game, a hierarchical Bayesian learning model predicts that sparse observations of a partner's language use may license much broader inferences about their lexicon via diagnostic information about their social group or background. If someone's favorite song is an obscure B-side from an obscure punk single, you can make fairly strong inferences about what else they like to listen to and how similar they might be to you \cite{VelezEtAl16_Overlaps, GershmanEtAl17_StructureSocialInfluence}. Similarly, if someone casually refers to an obscure New York landmark you also recognize, you can safely update your beliefs about their lexicon to include a number of other conventions shared among New Yorkers. Lexica cluster within social groups, so inverting this relationship can yield rapid lexical learning from inferences about social group membership.

This source of lexical learning was explored in a study by \citeA{IsaacsClark87_ReferencesExpertsNovices} where novices and experts were paired for a repeated reference game using postcards of New York landmarks. Both directors and matchers could be either novices or experts, creating a 2x2 design. While a strong main effect of reduction was found across all pairings of experts and novices, they differed strikingly in their use of proper nouns (i.e. conventions shared by experts). For instance, over the course of the experiment, experts consistently used short messages with proper nouns (e.g. ``the Rockefeller Center'') when talking to other experts, while novice directors gradually adapted to expert matchers, doubling their use of proper names (and therefore drastically reducing the length of their utterances).

Most striking, however, was the observation that directors had already adapted in the first few trials of the first round: by the fourth round expert directors were already using a proper noun three times more often when talking to other directors than in talking to novices. In fact, independent raters were presented with transcripts from the first two postcards and correctly judged the expertise of the two partners 84\% of the time. This is a straightforward prediction of a hierarchical Bayesian model: given a latent group representation of New Yorkers, a director can make a strong prediction that if their partner belongs to this group, ``Rockefeller Center'' will belong to their lexicon with high probability. Hence, any interpretation failure is strong evidence that their partner is not in the group and is thus equally unlikely to recognize ``Citicorp Building'' or ``Brooklyn Bridge''. In this way, convention formation and social group inference are intimately intertwined. 

\section{Generalization}

If the local conventions -- or lexical pacts -- formed over the course of an interaction reflect lexical learning, then what are the boundaries of that learning? How do meanings learned in one context transfer to new contexts? When can a peculiar meaning be explained away as the idiosyncrasy of a particular partner, and when does it become a generic lexical expectation or global convention? In this section, we discuss four empirical properties of generalization that computational models of convention formation must account for. Over short time scales, lexical pacts are \emph{partner-specific} but sticky across \emph{contexts} and sufficiently similar \emph{objects}. Over longer time scales, however, as agents repeatedly interact with multiple partners in larger social networks, local pacts generalize to global conventions expected to be shared across the entire \emph{community}.

\subsection{Generalization from one partner to another}

The mechanisms for coordinating on local conventions or pacts within an interaction are the same that support general language-learning. 

One of the most obvious criticisms of a strong interpretation of reduction as evidence of convention formation is that it is just a product of individual learning or conceptual refinement on the part of the speaker and really has nothing to do with the communication task or partner at all. There are two main responses to this criticism: (1) the director's initial description strongly depends on the intended audience and (2) reduction is idiosyncratic and partner-specific -- if the experimenter intervenes and swaps out partners, directors revert to longer messages until new conventions are again established. 

While social reasoning is already apparent there is abundant evidence that the conventions formed over the course of interaction are partner-specific: in other words, the speaker is learning a specific model of their partner's language, not just privately forming an association between words and objects. 

The ability to actively \emph{give} feedback is also critical for the listener to learn effectively \cite{SchoberClark89_Overhearers}. \todo[inline]{Tangrams w/ overhearer; Compare to equivalent finding w/ graphical conventions in Garrod et al (2007), expt. 3. Think about how to accommodate the effect of listener feedback in model? }

Outside of repeated reference games, there is also evidence that listeners adapt their interpretation of \emph{quantifiers} like \emph{some} and \emph{many} after repeated exposure \cite{Yildirim16_TalkerSpecificityQuantifiers}.

Weber \& Camerer (2003) showed that? 

Yoon \& Brown-Schmidt
\begin{itemize}
\item Brennen \& Clark, 1996 (Compare ahistorical i.e. pure informativity vs. various historical models: recency, frequency, provisionality, partner-specificity)
\item Exp. 1: 50\% of players kept overinformative label (`pennyloafer') after switching to less `close' context when there's only one shoe
\item Wilkes-Gibbs \& Clark, 1992
\item Switched out partner after 6 rounds; resets w/ naive partner (vs. what you'd expect if it was just practice)
\item Metzing and Brennan (2003)
\item Duff \& Brown-Schmidt stuff
\end{itemize}

Enriches pure cross-situational models w/ hierarchical model (see Eve Clark textbook)

\begin{itemize}
\item Glucksberg, Krauss, \& Weisberg, 1966
\item Devo version of experiment; kids don't converge on name
\item (see Krauss \& Glucksberg, 1969 for error analysis but they don't report words)
\end{itemize}

\subsection{Generalization from one context to another}

Remarkable stability: more variability across pairs than within pairs. 

\todo[inline]{Discuss Brennen \& Clark, 1996; pennyloafer; stickiness}

The stickiness of conventions has been challenged recently by \citeA{MisyakEtAl16_InstantaneousConventions} using a repeated reference game using simple tokens to communicate instead of words.

\subsection{Generalization from object to categories}

\cite{MarkmanMakin98_ReferentialCommunicationCategory}

\cite{MaltSloman04_ConversationConvention}

\subsection{Generalization from individual to community}

\begin{itemize}
\item Caldwell \& Smith, 2012
\item Replicated Garrod et al (2007) with microsocieties; argued that repeated reference within isn't necessary for conventionalization \& simplification
\item Garrod \& Doherty, 1994
\item Compare dyad vs. community on mazes games
\item Centola \& Baroncelli, 2015
\item Network architectures for population-level emergence
\item Fay et al, 2010 
\item Community-based version of pictionary
\item Garrod et al (2010)
\item Directly compare vertical and horizontal transmission
\end{itemize}

It is clear how global conventions shape the formation of local conventions. They form the prior distribution from which we assume a novel partner's lexicon is drawn. The natural language games we've reviewed %in the tradition of Krauss \& Weinheimer (1964) and Clark \& Wilkes-Gibbs (1986) 
implicitly rely on the fact that participants share the same native tongue to get communication off the ground. Lengthy initial descriptions are only useful because both participants share strong beliefs about the meanings of words in general, even if those global conventions aren't sufficient for efficiently naming these particular novel stimuli in this context. 

But where do global conventions come from in the first place? Some are certainly based on assumptions about shared perceptual systems. Iconic meanings derive directly from perceptual experience and thus hold across language communities -- onomatopoeia, for example, or the sound-symbol association of kiki with sharp objects and boba with smooth objects. Yet for the arbitrary form-meaning mappings that make up the bulk of our linguistic lexicon, it is difficult to imagine any mechanism for their emergence that doesn't first pass through local conventions. How do interactions with a single partner shape one's prior for interactions with other partners, and how do these priors converge across social networks? 

By allowing participants to interact with multiple partners, several studies have used iterated reference games to probe this pathway. 

Healey et al (2007) split participants into several `communities' -- each participant first played 12 rounds of a reference game with members of their own community. In this game, they concurrently drew sketches on the same sketchpad to determine whether pieces of music they heard were the same or different, and no target pieces were repeated. Thus, across this phase of the experiment, they are increasingly likely to be paired with others who have an indirect connection in the network: who have also met their previous partners or partner's partners. After several rounds of this procedure, they enter a `test' phase of the experiment, where they are either paired with a novel member of their own community or a member of a different community (without being explicitly told which it is). In either case, their partner is novel, but only in the in-group condition does a hierarchical learning account predict that should they should share similar priors, or global conventions for communicating. Indeed, they found that participants required more ink to succeed with an out-group member, and that drawings were more likely to shift to a ''Figurative'' style and thus be more interpretable without shared task-specific conventions (as opposed to the ``Abstract'' drawings more common within an in-group). 

\section{Discussion}

\subsection{Convention-formation across modalities}

%\begin{quote}
%the oral modality assumed the segmented and combi- natorial code not because of its strengths but to com- pensate for its weaknesses. The oral modality is not well suited to conveying messages mimetically [i.e., iconically], even though that function is also important to human languages. This function is, however, very well served by the manual modality'' (Goldin-Meadow and McNeill, p. 155).
%\end{quote}

While most studies of adaptation and convention formation have focused on spoken or written language, there has been a recent surge of interest in exploring similar temporal dynamics in other communication modalities. This line of research is relevant for our proposal in several ways. First, it is a core claim of the hierarchical learning hypothesis that the mechanisms underlying adaptation and convention formation are domain-general. In other words, there's nothing special about spoken or written language; any ad hoc system that we use to communicate and coordinate with other minds should display similar learning dynamics because they are all subject to the same functional pressures. 

Second, because the hierarchical learning hypothesis claims a critical role for the global priors we build up across many interactions with many individuals, we predict that different communication modalities should nevertheless display certain systematic differences in their dynamics. For example, consider a reference game where the targets are complex, abstract geometric shapes. In the verbal modality, these shapes are highly innominate -- we don't have much experience naming or describing them with words, thus our global prior is rather weak and we expect local adaptation to play a much bigger role. In the graphical modality, where you must communicate by drawing on a sketchpad, on the other hand, you have a much stronger prior because every observer's perceptual system can be assumed to share the ability to assess visual similarity (though note that explaining these similarity judgements presents its own challenges). Other stimuli have precisely the opposite property: to distinguish between natural images of dogs, for instance, we may have very strong priors in the linguistic modality (e.g. `husky', `poodle', `pug', etc) but drawing the necessary fine distinctions in the graphical modality may be initially very costly, encouraging the formation of local conventions. 

Practically speaking, then, considering iterated reference games across different modalities is necessary to (1) test which adaptation effects, if any, are robust \& attributable to general mechanisms and (2) explain variance across settings where global priors and local adaptation trade off in different ways. If we stuck solely to the verbal modality, we would be limited to a fairly narrow range of stimuli (e.g. abstract shapes/tangrams) where behavior in the lab isn't totally dominated by strong prior conventions people bring into the interaction. Here, we briefly review key results in the two non-linguistic modalities where there is now a critical mass of interest: drawing and gesture. While most of the studies were conducted under the auspices of experimental semiotics, placing the focus on how novel communication systems emerge and develop certain properties in the first place, we mine them for evidence of flexibility and adaptation inside the mind. 

The clearest analogs to repeated linguistic reference games in the style of Krauss \& Weinheimer (1964) are the interactive Pictionary games first introduced experimentally by Healey et al (2007) and \citeA{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems}
\footnote{Healey et al (2001) introduced an earlier version of the music drawing game, but for the purposes of this review, no piece appeared as the target more than once and the only dynamics reported were moderate levels of coordination on similar drawing types as coded by judges (i.e. player 1 is more likely to use Figurative drawings than Abstract drawings when player 2 also uses Figurative drawings). Similarly, Healey et al (2002) gives a brief overview of several repeated designs, but these data apparently only appear with full details in later publications.
}, 
where participants were given a whiteboard to draw on instead of an auditory channel to talk through. For example, Garrod et al (2007) used a set of 12 concept words as targets (``Robert de Niro'', ``poverty''), which the drawer was assigned in a randomized order. The viewer was also given a list of these words, which also included four distractors for a total context size of 16, and the drawer was instructed to produce some graphical message for each concept so that the viewer could re-rank their list in the same order. After drawing all twelve words, the lists were shuffled and the pair referred to each several more times. Similar to the reduction of tangram descriptions over the course of multiple rounds, Garrod et al (2007) found that drawings became gradually simpler as the game progresses, provided that the right feedback mechanisms are in place (see Section X). 

Corresponding effects have been found in repeated graphical communication games where participants use a white board instead of an audio channel \cite<e.g.>{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems}. In the complete absence of feedback, drawings also fail to reduce and in some cases grow more complex over time. Successively richer feedback mechanisms, however, do seem to increase the rate of reduction, like allowing the viewer to go through one or more rounds of `marking up' the drawing after it is completed (similar to repair or turn-taking in linguistic channels), swapping roles each round, or giving concurrent feedback by drawing side-by-side instead of waiting until completion (similar to verbal backchannels). Graphical experiments also allow for more fine-grained comparison of concurrent feedback: a non-repeated design provided evidence that coordination is impeded if participants are forced to draw in different boundaries of the screen, or if these boundaries are transposed across screens, preventing arrows or reference to elements of a partner's drawing. 

\begin{itemize}
\item Theisen et al, 2010 (Adaptation of Garrod et al 2007 focusing on systematicity)
\end{itemize}

A final modality-based method to examine learning is to attempt to destroy or scramble any meaningful priors that people might carry into the social interaction. For example, Galantucci (2005) introduced a novel `seismograph' interface for communication -- a stylus that could be moved side-to-side or lifted up or down to make contact with the sketch pad while the vertical dimension drifted downward at a constant rate. The resulting messages consequently look nothing like the usual kinds of symbols people create: the relationship between motor actions and perceptual output is broken such that executing a familiar movement for a symbol or numeral instead produces an odd, wavy scribble. 

This same interface was adapted for a more straightforward reference game where the referents were animal silhouttes (Roberts and Galantucci, 2012) or colors and line segments (Roberts et al, 2015). 

Other novel modalities used in iterated reference games include a `whistle' language where movements along a vertical touch bar slider correspond to changes in pitch (Verhoef et al, 2015); a visual analog where movements along the slider were presented visually (Verhoef et al, 2016); and 

\subsection{Coordination at other levels}

While we have thus far limited our discussed specifically to the reduction and simplification of messages as participants coordinate on meanings given a shared set of referents, this is only one of many levels at which conventions can form. In more complex circumstances, there is often initial uncertainty not just about which of a small set of targets a particular message refers to, but how to represent the relevant targets of reference in the first place. For instance, when using sketches to communicate about the identity of complex pieces of music (Healey et al, 2007), a particular set of strokes could correspond to any number of properties (pitch, tempo, melody, rhythm, intensity) at any temporal granularity. This requires another layer of coordination that must be jointly learned along with the mappings themselves. 

To see how our hierarchical learning account can be extended to these cases, we consider the classic study by Garrod \& Anderson (1987) where participants were paired for a maze navigation task. 

\todo[inline]{Garrod \& Anderson, 1987 Mazes}
\todo[inline]{Schober, 1993?
``When interlocutors face each other, terms like on the left are ambiguous depending on whether the speaker takes what we can call an egocentric or an allocentric reference frame. Schober found that if, for instance, A said on the left meaning on A's left (i.e., an egocentric reference frame), then B would subsequently describe similar locations as on the right (also taking an egocentric frame of reference)''}
\todo[inline]{Dale et al, 2011: Don't analyze linguistic data but show that eyes/hands become coordinated over course of tangrams task}

Nonetheless, Galantucci found that most partners were able to jointly learn a shared communication system to solve repeated spatial coordination tasks in a relatively short span of time. In the simplest version of this task, each player was placed in one of four rooms on a map, with the identity of a room marked only by large symbols. They were rewarded for finding one another in one room-change or less, and therefore needed to use their communication channel to convey information about their position and where to go. Note that this game contains the same basic structure as a basic tangram-style reference game where there are four `targets' (rooms marked by shapes) that must repeatedly be referred to: it is just embedded inside a considerably more complex set of strategic and spatial challenges. The average time to converge on an effective system was a little over an hour. 

From the perspective of learning, this is an incredible feat: because participants were basically told nothing before beginning play, they had to infer the spatial structure of the map, the categorical structure of strokes used by their partner (e.g. when are two distinct percepts the same `sign'), the meaning of each stroke (e.g. which stroke corresponds to which room? Is it a request like `let's go here' or a statement like `I am here'?), and so on, all from fairly sparse and noisy feedback. Unfortunately, any universal conclusion about how participants managed this feat was difficult to draw: only ten pairs played the game, and essentially every pair found a different solution. Still, these solutions bear the same qualitative signatures of the convention formation process found in all iterated communication games: when prior conventions are not sufficient for the task at hand, partners rapidly learn arbitrary and path-dependent but stable solutions from observing one another's behavior in early rounds. 

\todo[inline]{brief call-out to, like, Selten \& Warglien, 2007 where dyads used ``string of permissable letters'' like ``RM''? Not quite reference game b/c both players typed messages that had to match? Main focus was on compositional grammar? }

\subsection{Mechanisms for learning}

\cite{DuffBrownSchmidt12_Hippocampus}

%\subsection{Other theories and models of convention formation in repeated reference games.}
%
%Our assumption of a probabilistic, context-sensitive lexical prior can be contrasted with the more dominant view of the lexicon as a monolithic representation of lexical knowledge acquired across our individual experience with language use. Instead of engaging theory of mind to represent a partner's lexicon, then, we could just heuristically substitute our own representation as an approximation   \cite{Steels03_GroundedCommunication,JonesEtAl15_SemanticMemory}. %This position is typical of process-level models focusing on, 
%Note that this `egocentric' heuristic would be completely rational under strong conventional assumptions of common ground: if everyone assumes mutual knowledge of this lexicon is shared across their community, then it is in everyone's best interest to adhere to identical meanings, and reasonable to expect that a particular partner in the community is doing so. Yet we will see that it falls short in accounting for partner-specific effects.
%
%A number of distinct theoretical accounts have been offered to make sense of pieces of this large body of results. These accounts roughly divide into two camps: the `minimalists' and the `maximalists.' The minimalists seek to identify the simplest set of mechanisms that, when implemented in a communicative agent, will give rise to some conventional phenomena. Often these mechanisms involve low-level priming or simple `if-then' heuristics and strongly reject the need for any representation of `other-modeling.' The maximalists, on the other hand, argue that partner-specific adaptation -- when studied in its full real-world complexity -- can only be explained by viewing dialogue as a structured, collaborative interaction between agents using more sophisticated social reasoning mechanisms. 
%
%\begin{itemize}
%\item Barr, 2004
%\item Steels, 2005; 2015, Vogt, 2005
%\item Centola \& Baroncelli, 2015
%\item Shoham \& Tennenholtz, 1997 (Keep a memory of actions people have taken over the last m rounds and adopt the one that led to the highest payoff (intended to account for global interactions))
%Agents themselves not probabilistic, so a particulate pair 
%\item Garrod \& Pickering, 2004 (interactive alginment) 
%\item Clark \& wilkes-gibbs (1986 etc) collaborative model
%\end{itemize}

% There are many other intermediate mechanisms for feedback that remain unexplored: restricting concurrent feedback but allowing the director to see which item was picked; allowing the matcher to interrupt the continuous message at any point with their guess; allowing the director to continuously track the matcher's current guess over the course of creating their message.

\section{Conclusion}

Language is not some monolithic body of knowledge that we acquire at an early age and deploy mechanically for the rest of our lives. Nor is its evolution a slow, inter-generational drift. It is a means for communication -- a shared interface between minds -- and must therefore adapt over the rapid timescales required by communication. In other words, we are constantly learning language. Not just one language, but an enormous family of related languages, across every repeated interaction with every partner. 


\section{\bf Acknowledgments}
\small
\noindent RXDH was supported by the Stanford Graduate Fellowship and the National Science Foundation Graduate Research Fellowship under Grant No. DGE-114747.

\singlespacing
\bibliography{cada}
\bibliographystyle{apacite}


\end{document}  
