///fold:
var initList = function(n, val) {
  return repeat(n, function() {return val})
}

var uniformPs = function(vs) {
  return initList(vs.length, 1/vs.length)
}

var possibleWords = ['the', 'ki', 'ma'];

var deleteWords = function(words) {
  if(_.isEmpty(words)) {
    return words;
  } else {
    var wordToOmit = uniformDraw(words);
    return remove(wordToOmit,words);
  }
};

var insertWords = function(words) {
  var insertLoc = randomInteger(words.length + 1);
  var insertWord = uniformDraw(possibleWords);
  return (words.slice(0,insertLoc)
         .concat(insertWord)
         .concat(words.slice(insertLoc, words.length)));
};

var replaceWords = function(words) {
  if(_.isEmpty(words)) {
    return words;
  } else {
    var replaceLoc = randomInteger(words.length);
    var replaceWord = uniformDraw(possibleWords);
    return (words.slice(0,replaceLoc)
            .concat(replaceWord)
            .concat(words.slice(replaceLoc+1,words.length)));
  }  
};

var nullMeaning = function(x) {return true;};
var constructMeaning = function(label) {
  return function(trueState) {
    return any(function(labelState){
      return labelState == trueState;
    }, label.split('|'));
  }
};
var negate = function(f) {return function(x) {return !f(x)};}
var identity = function(x) {return x;};
var getRatio = function(model) {
  return Math.exp(model.score('ki') - model.score('ki ma'))
}

var initList = function(n, val) {
  return repeat(n, function() {return val})
}

var uniformPs = function(vs) {
  return initList(vs.length, 1/vs.length)
}

var dProbs = [.01, .25, .5, .75, 0.99]
///

// possible states of the world
var states = ['t1', 't2'];
var statePrior =  Categorical({vs: states, ps: [1/2, 1/2]});

// possible utterances (include null utterance to make sure dists are well-formed)
var grammaticalUtts = ['the ma', 'the ki'];
var intentionallyCorruptedUtts = ['the', 'ma', 'ki', 'ma ki'];
var intendedUtts = grammaticalUtts.concat(intentionallyCorruptedUtts)
var utterancePrior = Categorical({vs: grammaticalUtts, ps: uniformPs(grammaticalUtts)});

// takes a sample from a (discretized) dirichlet distribution for each word,
// representing the extent to which that word describes each object
var lexiconPrior = Infer({method: 'enumerate'}, function(){
  var meanings = map(function(utt) {
    var t1Prob = categorical({vs: [0.01, 0.25, .5, .75, .99], 
                              ps: [.2, .2, .2, .2, .2]})
    return {'t1' : t1Prob, 't2' : 1-t1Prob};
  }, grammaticalUtts);
  return _.object(grammaticalUtts, meanings);
});

// length-based cost 
var uttCost = function(utt) {
  return utt.split(' ').length > 1 ? 1.1 : 1;
};

var params = {
  alpha: 1,
  noiseRate: 0.1,
  maxDepth: 2
}

// Recursively edit string to maxDepth (log prob proportional to levenstein distance)
var transform = function(words, currDepth) {
  if(flip(1 - params.noiseRate) || currDepth > params.maxDepth) {
    return _.isEmpty(words) ? [''] : words;
  } else {
    var operations = [deleteWords, insertWords, replaceWords];
    var op = uniformDraw(operations);
    return transform(op(words), currDepth + 1);
  }
};

// Gives distribution over possible noisy versions of intended utt
var noiseModel = cache(function(utt) {
  return Infer({method: 'enumerate'}, function() {
    return (utt === 'n0' ? 'n0' :
            transform(utt.split(' '), 0).join(' '));
  });
});

// literal listener w/ noisy channel inference
// Note that the -100s are hacks to make it well-formed after capping recursion:
// a corruption of a corruption may not be reachable from a corruption of a grammatical utt,
// and it's possible that none of the reachable meanings are true of any of the states
var L0 = cache(function(utt, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var state = sample(statePrior);
    var intendedUtt = sample(utterancePrior)

    var noiseScore = (_.contains(noiseModel(intendedUtt).support(), utt) ?
                      noiseModel(intendedUtt).score(utt) :
                      -100)
    factor(Math.log(lexicon[intendedUtt][state]) + noiseScore);
    return state;
  });
});

// pragmatic speaker marginalizing over perceptual corruption in L0
var S1 = cache(function(state, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var intendedUtt = uniformDraw(intendedUtts)
    var listener = Infer({method: 'enumerate'}, function(){
      var corruptedUtt = sample(noiseModel(intendedUtt));
      return sample(L0(corruptedUtt,lexicon))
    })

    factor(params.alpha * listener.score(state) 
           - uttCost(intendedUtt));
    return sample(noiseModel(intendedUtt));
  });
});

// pragmatic listener (needed for S)
var L1 = cache(function(perceivedUtt, lexicon) {
  return Infer({method: 'enumerate'}, function() {
    var state = sample(statePrior);
    observe(S1(state, lexicon), perceivedUtt);
    return state;
  });
});

var lexiconPosterior = cache(function(originAgent, data) {
  return Infer({method: 'enumerate'}, function() {
    var lexicon = sample(lexiconPrior);
    mapData({data: data}, function(datum){
      if(originAgent === 'L') {
        observe(S1(datum.obj, lexicon), datum.utt);
      } else if(originAgent === 'S') {
        observe(L1(datum.utt, lexicon), datum.obj);
      }
    });
    return lexicon;
  });
});

// conventional listener (L1, marginalizing over lexicons)
var L = function(utt, data) {
  return Infer({method:"enumerate"}, function(){
    var lexicon = sample(lexiconPosterior('L', data));
    var state = sample(L1(utt, lexicon));
    return state;
  });
};

// conventional speaker
var S = function(state, data) {
  return Infer({method:"enumerate"}, function(){
    var intendedUtt = uniformDraw(intendedUtts);
    var listener = Infer({method: 'enumerate'}, function(){
      var lexicon = sample(lexiconPosterior('S', data));
      var corruptedUtt = sample(noiseModel(intendedUtt))
      return sample(L1(corruptedUtt, lexicon))
    })
    
    factor(params.alpha * listener.score(state) - uttCost(intendedUtt));
    return intendedUtt;
  });
};

viz(S('t1', []))
viz(S('t1', [{obj: 't1', utt: 'the ki'}]))

// console.log("respective ratios of 'ki' to 'kima' (increasing is good)")
// print(getRatio(S('t1', [{utt: 'ki ma', obj: 't1'}])))
// print(getRatio(S('t1', [{utt: 'ki ma', obj: 't1'},
//                         {utt: 'fu ba', obj: 't2'}])))
// print(getRatio(S('t1', [{utt: 'ki ma', obj: 't1'},
//                         {utt: 'fu ba', obj: 't2'},
//                         {utt: 'ki ma', obj: 't1'}])))