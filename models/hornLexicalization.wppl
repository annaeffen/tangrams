var getTrajectories = function(data) {
  var keys = _.keys(data[0]);
  return reduce(function(key, memo) {
    var timeBasedKeys = map(function(i) {return key + "." + i;}, _.range(data.length));
    var vals = _.map(data, key);
    return extend(_.zipObject(timeBasedKeys, vals), memo);
  }, [], keys);
};

// possible states of the world
var states = ['rare', 'common'];
var statePrior =  Categorical({vs: states, ps: [.2, .8]});

// possible utterances (include null utterance to make sure dists are well-formed)
var utterances = ['cheap', 'expensive'];
var utterancePrior = Categorical({vs: utterances, ps: [.5, .5]});

// takes a sample from a dirichlet distribution for each word,
// representing the extent to which that word describes each object
var lexiconPrior = function(){
  var meanings = map(function(utt) {
    var t1Prob = uniformDrift({a:0,b:1,width:.1});
    return {'rare' : t1Prob, 'common' : 1-t1Prob};
  }, utterances);
  return _.zipObject(utterances, meanings);
};

// set speaker optimality
var params = {
  alpha : 3,
  beta : 1,
  numSteps: 6
};

// 'cheap' is cheaper than 'expensive'
var uttCost = function(utt) {
  return (utt == 'cheap' ? .5 : 
          utt == 'expensive' ? 1 :
          10);
}

// literal listener (using real-valued lexicon)
var L0 = function(utt, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var state = sample(statePrior);
    factor(Math.log(lexicon[utt][state]));
    return state;
  });
};

// pragmatic speaker 
var S1 = function(state, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var utt = sample(utterancePrior);
    factor(params.alpha * (L0(utt, lexicon).score(state) - uttCost(utt)));
    return utt;
  });
};

// conventional listener
var L1 = function(utt, lexicon) {
  return Infer({method:"enumerate"}, function(){
    var state = sample(statePrior);
    observe(S1(state, lexicon), utt);
    return state;
  });
};

// compute lexicon posterior, taking into account some previous observations
// speakers do this by assuming data came from knowledgable listener, and vice versa
var lexiconPosterior = cache(function(originAgent, data) {
  setFreshParamsId();
  return Infer({method: 'MCMC', samples: 1000, verbose: false, onlyMAP: true}, function() {
    var lexicon = lexiconPrior();
    mapData({data: data}, function(datum){
      if(originAgent === 'L') 
        observe(S1(datum.response, lexicon), datum['utt']);
      else if(originAgent === 'S') 
        observe(L1(datum.utt, lexicon), datum['response']);
    });
    return lexicon;
  });
});

// conventional listener (L1, marginalizing over lexicons)
var L = function(utt, data) {
  return Infer({method:"enumerate"}, function(){
    var lexicon = sample(lexiconPosterior('L', data));
    var state = sample(L1(utt, lexicon));
    return state;
  });
};

// conventional speaker (S1, reasoning about expected L1 behavior across lexicons)
var S = function(state, data) {
  return Infer({method:"enumerate"}, function(){
    var utt = sample(utterancePrior);
    var listener = Infer({method: 'enumerate'}, function() {
      var lexicon = sample(lexiconPosterior('S', data));
      return sample(L1(utt, lexicon));
    });
    factor(params.alpha * (listener.score(state) - uttCost(utt)));
    return utt;
  });
};

var model = function() {
  console.log('sampling...');
  var step = function(data) {
    if(data.length > params.numSteps) return getTrajectories(data);
    console.log(data.length);
    var state = sample(statePrior);
    var utt = sample(S(state, data));
    var response = sample(L(utt, data));
    var newDatum = {utt, response, intended: state, acc: state == response};
    return step(data.concat(newDatum));
  };
  step([]);
};

Infer({method: 'forward', samples: 100}, model);
